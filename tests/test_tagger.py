"""íƒœê·¸ ì¶”ì¶œ + í•„í„°ë§ ìˆ˜ë™ í…ŒìŠ¤íŠ¸"""
from src.collectors.rss_collector import RSSCollector
from src.summarizer.llm_summarizer import LLMSummarizer
from src.tagger.tag_extractor import TagExtractor, TagFilter


def main():
    # 1. RSS ìˆ˜ì§‘ (3ê±´ë§Œ)
    collector = RSSCollector()
    entries = collector.collect_all()[:3]

    if not entries:
        print("âŒ ìˆ˜ì§‘ëœ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ìš”ì•½
    summarizer = LLMSummarizer()
    summarized = summarizer.summarize_batch(entries)

    # 3. íƒœê·¸ ì¶”ì¶œ
    extractor = TagExtractor()
    print(f"\nğŸ·ï¸ íƒœê·¸ ì¶”ì¶œ ì‹œì‘...")

    articles = []
    for item in summarized:
        entry = item["entry"]
        print(f"  [{entry.title[:40]}...]")
        tags = extractor.extract_tags(entry.title, entry.content, entry.tags)
        print(f"    â†’ {', '.join(tags)}")

        articles.append({
            "entry": entry,
            "summary": item["summary"],
            "tags": tags,
        })

    # 4. ê´€ì‹¬ íƒœê·¸ í•„í„°ë§
    tag_filter = TagFilter(interest_tags=["python", "fastapi", "ai", "backend"])
    relevant = tag_filter.filter_relevant(articles)

    print(f"\n{'='*60}")
    print(f"ğŸ¯ ê´€ì‹¬ íƒœê·¸ í•„í„°ë§ ê²°ê³¼: {len(relevant)}/{len(articles)}ê±´ ê´€ë ¨")
    print(f"{'='*60}\n")

    for r in relevant:
        entry = r["entry"]
        rel = r["relevance"]
        print(f"ğŸ“Œ {entry.title}")
        print(f"   ğŸ·ï¸ íƒœê·¸: {', '.join(r['tags'])}")
        print(f"   ğŸ¯ ë§¤ì¹­: {', '.join(rel['matched_tags'])} (ì ìˆ˜: {rel['score']})")
        print()


if __name__ == "__main__":
    main()