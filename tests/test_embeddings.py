"""ì„ë² ë”© + ê¸€ ë¶„ë¥˜ ìˆ˜ë™ í…ŒìŠ¤íŠ¸"""
import numpy as np

from src.embeddings.embedding_service import EmbeddingService, ArticleClassifier
from src.collectors.models import FeedEntry
from datetime import datetime, timezone


def make_dummy_entry(title: str, tags: list[str]) -> dict:
    """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ê¸€ ìƒì„±"""
    entry = FeedEntry(
        title=title,
        url=f"https://example.com/{title.replace(' ', '-')}",
        author="tester",
        published=datetime.now(tz=timezone.utc),
        content=title,
        platform="test",
        feed_name="test feed",
        tags=tags,
    )
    return {
        "entry": entry,
        "summary": {"summary": title, "lines": [title], "success": True},
        "tags": tags,
    }


def main():
    svc = EmbeddingService()

    # 1. ê¸°ë³¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸
    print("=== ê¸°ë³¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ===\n")
    texts = [
        "FastAPIë¡œ REST API ì„œë²„ ë§Œë“¤ê¸°",
        "Djangoì™€ FastAPI ë¹„êµ ë¶„ì„",
        "ìŠ¤íƒ€ë“€ë°¸ë¦¬ ë†ì‚¬ ê°€ì´ë“œ",
    ]
    vectors = svc.encode_batch(texts)
    print(f"ë²¡í„° ì°¨ì›: {vectors.shape}")

    for i in range(len(texts)):
        for j in range(i + 1, len(texts)):
            sim = svc.cosine_similarity(vectors[i], vectors[j])
            print(f"  '{texts[i][:20]}...' â†” '{texts[j][:20]}...' = {sim:.4f}")

    # 2. ê¸€ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
    print(f"\n=== ê¸€ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ===\n")

    # ì½ì€ ê¸€ (Python/ë°±ì—”ë“œ ê´€ë ¨)
    read_texts = [
        "Python FastAPI íŠœí† ë¦¬ì–¼ íƒœê·¸: python, fastapi, backend",
        "SQLAlchemy ORM ì‚¬ìš©ë²• íƒœê·¸: python, database, orm",
        "Dockerë¡œ ê°œë°œí™˜ê²½ êµ¬ì¶• íƒœê·¸: docker, devops",
    ]
    read_vectors = svc.encode_batch(read_texts)

    # ìƒˆ ê¸€ í›„ë³´
    new_articles = [
        make_dummy_entry("FastAPI ë¯¸ë“¤ì›¨ì–´ ì‘ì„±ë²•", ["python", "fastapi"]),
        make_dummy_entry("React 18 ë™ì‹œì„± ê¸°ëŠ¥ ì†Œê°œ", ["react", "frontend"]),
        make_dummy_entry("PostgreSQL ì¸ë±ìŠ¤ ìµœì í™”", ["database", "postgresql"]),
        make_dummy_entry("Kubernetes ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì „ëµ", ["kubernetes", "devops"]),
    ]

    classifier = ArticleClassifier(svc)
    classifier.update_read_history(read_vectors)
    result = classifier.classify(new_articles, threshold=0.5)

    print(f"ğŸ”„ ë¹„ìŠ·í•œ ê¸€ ({len(result['familiar'])}ê±´):")
    for item in result["familiar"]:
        title = item["article"]["entry"].title
        print(f"  ğŸ“– {title} (ìœ ì‚¬ë„: {item['max_similarity']})")

    print(f"\nğŸ†• ìƒˆë¡œìš´ ê¸€ ({len(result['novel'])}ê±´):")
    for item in result["novel"]:
        title = item["article"]["entry"].title
        print(f"  ğŸ” {title} (ìœ ì‚¬ë„: {item['max_similarity']})")


if __name__ == "__main__":
    main()