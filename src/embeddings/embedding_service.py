import numpy as np
from sentence_transformers import SentenceTransformer

from config.settings import settings


class EmbeddingService:
    """ë¬¸ì¥ ì„ë² ë”© ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚°"""
    
    def __init__(self, model_name: str | None = None):
        self.model_name = model_name or settings.embedding_model_name
        self._model = None
    
    @property
    def model(self) -> SentenceTransformer:
        """ëª¨ë¸ ì§€ì—° ë¡œë”© (ì²« í˜¸ì¶œ ì‹œ ë¡œë“œ)"""
        if self._model is None:
            print(f"ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {self.model_name}")
            self._model = SentenceTransformer(self.model_name)
            print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ì°¨ì›: {self._model.get_sentence_embedding_dimension()})")
        return self._model
    
    @property
    def dimension(self) -> int:
        return self.model.get_sentence_embedding_dimension()
    
    def encode(self, text: str) -> np.ndarray:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        return self.model.encode(text, normalize_embeddings=True)
    
    def encode_batch(self, texts: list[str], batch_size: int = 32) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¼ê´„ ë²¡í„°ë¡œ ë³€í™˜"""
        return self.model.encode(
            texts,
            normalize_embeddings=True,
            batch_size=batch_size,
            show_progress_bar=len(texts) > 10,
        )
    
    @staticmethod
    def cosine_similarity(vec_a: np.ndarray, vec_b: np.ndarray) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„° ê¸°ì¤€)"""
        return float(np.dot(vec_a, vec_b))
    
    @staticmethod
    def cosine_similarity_matrix(vectors_a: np.ndarray, vectors_b: np.ndarray) -> np.ndarray:
        """ë²¡í„° ê·¸ë£¹ ê°„ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°"""
        return np.dot(vectors_a, vectors_b.T)


class ArticleClassifier:
    """ì½ì€ ê¸€ ê¸°ë°˜ìœ¼ë¡œ ìƒˆ ê¸€ì„ 'ë¹„ìŠ·í•œ ê¸€' vs 'ìƒˆë¡œìš´ ê¸€'ë¡œ ë¶„ë¥˜"""
    
    def __init__(self, embedding_service: EmbeddingService | None = None):
        self.embnedding_service = embedding_service or EmbeddingService()
        self.read_vectors: np.ndarray | None = None
    
    def update_read_history(self, read_vectors: np.ndarray):
        """ì½ì€ ê¸€ ë²¡í„° ëª©ë¡ ê°±ì‹ """
        self.read_vectors = read_vectors
    
    def _make_article_text(self, title: str, tags: list[str], summary: str = "") -> str:
        """ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„± (ì œëª© + íƒœê·¸ + ìš”ì•½)"""
        parts = [title]
        if tags:
            parts.append(f"íƒœê·¸: {', '.join(tags)}")
        if summary:
            parts.append(summary)
        return " ".join(parts)
    
    def classify(
        self,
        articles: list[dict],
        threshold: float | None = None,
    ) -> dict:
        """
        ê¸€ ëª©ë¡ì„ 'ë¹„ìŠ·í•œ ê¸€'ê³¼ 'ìƒˆë¡œìš´ ê¸€'ë¡œ ë¶„ë¥˜
        
        Args:
            articles: [{"entry": FeedEntry, "summary": dict, "tags": list}, ...]
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸: settings.similarity_threshold)
        
        Returns:
            {
                "familiar": [{"article": dict, "max_similarity": float}, ...],
                "novel": [{"article": dict, "max_similarity": float}, ...],
            }
        """
        threshold = threshold or settings.similarity_threshold
        
        # ì½ì€ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì „ë¶€ 'ìƒˆë¡œìš´ ê¸€'
        if self.read_vectors is None or len(self.read_vectors) == 0:
            print("  â„¹ï¸ ì½ì€ ê¸°ë¡ì´ ì—†ì–´ ëª¨ë“  ê¸€ì„ 'ìƒˆë¡œìš´ ê¸€'ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
            return {
                "familiar": [],
                "novel": [{"article": a, "max_similarity": 0.0} for a in articles],
            }
        
        # ìƒˆ ê¸€ ë²¡í„° ìƒì„±
        new_texts = []
        for article in articles:
            entry = article["entry"]
            summary_text = article.get("summary", {}).get("summary", "")
            tags = article.get("tags", [])
            text = self._make_article_text(entry.title, tags, summary_text)
            new_texts.append(text)
        
        new_vectors = self.embnedding_service.encode_batch(new_texts)
        
        # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
        sim_matrix = EmbeddingService.cosine_similarity_matrix(new_vectors, self.read_vectors)
        
        # ë¶„ë¥˜
        familiar = []
        novel = []
        
        for i, article in enumerate(articles):
            max_sim = float(np.max(sim_matrix[i]))
            
            item = {"article": article, "max_similarity": round(max_sim, 4)}
            
            if max_sim >= threshold:
                familiar.append(item)
            else:
                novel.append(item)
        
        # ì •ë ¬: familiarëŠ” ìœ ì‚¬ë„ ë†’ì€ ìˆœ, novelì€ ìœ ì‚¬ë„ ë‚®ì€ ìˆœ
        familiar.sort(key=lambda x: x["max_similarity"], reverse=True)
        novel.sort(key=lambda x: x["max_similarity"])
        
        return {"familiar": familiar, "novel": novel}